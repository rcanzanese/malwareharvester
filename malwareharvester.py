#!/usr/bin/env python

"""malwareharvester.py

Collects malware samples from URL black lists or from the filesystem.  Crawls
commonly used URL blacklists.  Also downloads and archives samples from
malshare.  Collected samples are scanned using VirusTotal, and metadata are
stored in a MySQL database.
"""

# Copyright 2015 Ray Canzanese
# rcanzanese@gmail.com
#
# This file is part of malwareharvester.
#
# malwareharvester is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# malwareharvester is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with malwareharvester.  If not, see <http://www.gnu.org/licenses/>.

# TODO list
# - Change from urllib2 to requests.
# - Fully implement crawling of links.  Determine types / levels.
# - Move user configuration out of here.

import bs4
import hashlib
import time
import urllib.request as urllib2
import subprocess
import os
import tempfile
import argparse
import sys
import random
import virustotalinterface
import databaseinterface
import lxml.html
from lxml import etree
from zipfile import ZipFile
import requests

# Fill in with your path to store malware samples
MALWARE_PATH = "~/malware_samples/"

# Fill in with your API key to use malshare
MALSHARE_API_KEY = None

# Fill in with your VirusTotal API key
API_KEY = None

# Fill in with your database information
HOST = None
USER = None
PASSWORD = None
DATABASE = None

# Password typically used for zip archives
ZIPPASSWORD = b'infected'

# Only consider malware samples with these filetypes
GREYLIST = ["MS-DOS", "PE32", "DOS executable", "COM executable"]

# Ignore filetypes containing the following
BLACKLIST = ["archiv", "nstall"]

# Timeout for HTTP requests
TIMEOUT = 60


def process_malekal_zips(url, args):
    """Processes samples from zip files hosted at malwaredb.malekal.com"""

    _string = "./files.php?file="

    print("processing " + url + "index.php?page=" + str(args))
    r = requests.get(url + "index.php?page=" + str(args))
    dom = lxml.html.fromstring(r.text)
    malware_list = []

    # Processes all links looking for ones of the perscribed format
    for link in dom.xpath('//a/@href'):
        if link[0:len(_string)] == _string:
            md5 = link[len(_string):]
            if db.contains_md5(md5):
                print("Skipping...")
                continue
            else:
                malware_list.append("http://malwaredb.malekal.com" + link[1:])

    return malware_list


def process_cleanmx_xml(url, args):
    """Processes the clan-mx XML list.

    Does not consider the recent or response tags.  Tries every URL.
    """

    mwl_url = urllib2.urlopen(url, None, TIMEOUT)
    root = etree.fromstring(mwl_url.read())

    malware_list = []

    entries = root.find('entries')
    for entry in entries:
        malware_list.append(entry.find('url').text)

    return malware_list


def process_text_list(url, args):
    """Processes plaintext lists of URLs."""

    r = requests.get(url)
    malware_list = []
    for mw in r.text.splitlines():
        mw = mw.strip()
        if mw:
            if mw.startswith("http"):
                malware_list.append(mw)
    return malware_list


def process_rss_description(url, flag):
    """Processes RSS feeds where the URL is in the description tag."""
    mwl_url = urllib2.urlopen(url, None, TIMEOUT)
    soup = bs4.BeautifulSoup(mwl_url.read())
    raw = soup.find_all('description')
    raw = raw[1:]
    malware_list = []
    for l in raw:
        first = l.text.split(',')[0]
        if first.startswith(flag):
            malware_list.append(first[len(flag):])
    return malware_list


def process_malware(mw, source, source_url, filename):
    """Gets and processes the malware samples.

    Collects metadata and adds samples to the database.

    Keywork arguments:
    mw - the malware sample
    source - text description of malware source
    source_url - source URL
    filename - the original filename of the malware sample
    """

    # Skip this sample if it is already in the database
    sha1 = hashlib.sha1(mw).hexdigest()
    if db.contains_sha1(sha1):
        print("Already in the database")
        return

    # Entry will become the database entry
    entry = dict()
    entry['MD5'] = hashlib.md5(mw).hexdigest()
    entry['DateAdded'] = time.strftime('%Y-%m-%d %H:%M:%S %Z')
    entry['LastUpdated'] = entry['DateAdded']
    entry['SourceURL'] = source_url
    entry['Source'] = source
    entry['LastUpdated'] = entry['DateAdded']
    entry['Filename'] = entry['DateAdded'][:7] + '/' + \
        entry['MD5'] + '.exe.virus'

    # Saves to a tempfile and runs "file" to determine its type
    with tempfile.NamedTemporaryFile(delete=False) as tf:
        tf.file.write(mw)

    ftype = subprocess.check_output(["file", tf.name, "-b"])\
        .decode('ascii').strip()

    if ftype.find("Zip") >= 0:
        print("Processing ZIP file...")
        with open(tf.name, 'rb') as f:
            try:
                z = ZipFile(f)
            except Exception as e:
                print("Zip Error: " + str(e))
                z = None

            if z is not None:
                for zf in z.infolist():
                    try:
                        uz = z.read(zf)
                    except:
                        try:
                            uz = z.read(zf, pwd=ZIPPASSWORD)
                        except:
                            print("Zip Error:  Don't know the password")
                            break
                    process_malware(uz, source, source_url, zf.filename)

        os.remove(tf.name)
        return

    #TODO: fully implement crawling of links?
    elif ftype.find("HTML") >= 0:
        try:
            with open(tf.name, 'r') as f:
                stream = f.read()
                dom = lxml.html.fromstring(stream)
                for link in dom.xpath('//a/@href'):
                    #print(link)
                    #print(urllib.parse.urlparse(link))
                    pass
        except:
            pass

    os.remove(tf.name)

    whitelisted = False
    for test_type in GREYLIST:
        if ftype.find(test_type) == 0:
            whitelisted = True

            for bad_type in BLACKLIST:
                if ftype.find(bad_type) >= 0:
                    whitelisted = False
                    break
            break

    if whitelisted is False:
        print("Unwanted filetype.  Skipping")
        return

    #Lookup the virustotal information
    vt_data = vt.lookup_by_hash(sha1)

    # Add the easy stuff to the database:
    db.add_malware(sha1)

    if vt_data is None:
        # If there are no results, submit it to VirusTotal
        print("No virustotal data, submitting to virustotal")
        vt.submit_to_virustotal(str(filename), mw)
        entry['Detections'] = 0
        entry['Detectors'] = 0
    else:
        # Otherwise we need to put all the VT goodies in there
        db.update_dict(sha1, vt.parse_response(vt_data))

    # Save the malware sample
    malware_directory = os.path.join(MALWARE_PATH, entry["Filename"][:7])
    if not os.path.isdir(malware_directory):
        os.makedirs(malware_directory)
    malware_filename = os.path.join(MALWARE_PATH, entry['Filename'])
    with open(malware_filename, 'wb') as f:
        f.write(mw)

    # Update database entry with local data
    entry['FileType'] = ftype.strip()
    db.update_dict(sha1, entry)


def get_malware(malware_list, source):
    """ Gets malware samples from a URL list.

    Keyword arguments:
    malware_list -- list of urls to malware samples
    source -- text description of malware source
    """

    count = 0
    mw = None

    for l in malware_list:
        error = False
        l = l.strip()
        count += 1

        if not l.startswith('http'):
            l = 'http://' + l
        try:
            print(l)
        except:
            l = l.encode("ascii", 'ignore')
            print(l)

        sys.stdout.write(str(count) + '/' + str(len(malware_list)) + ":    ")

        #Get the file
        try:
            r = requests.get(l, timeout=15)
            mw = r.content
            if len(mw) == 0:
                print("Error no content")
                print(r.status)
                error = True
        except:
            print("Exception getting content")
            error = True

        if not error:
            process_malware(mw, source, l,
                l.split('/')[-1].encode('ascii', 'ignore'))


def get_malshare():
    """ Gets malshare malware samples from the current list

    Only grabs the sample if the MD5 is not in the dataabase already.  Limits
    to 1000 samples because of API limit enforced by malshare.
    """

    r = requests.get("http://www.malshare.com/daily/malshare.current.txt")

    urllist = r.text.splitlines()
    urllist.reverse()

    count = 0
    for mw in urllist:
        if count >= 1000:
            return

        mw = mw.strip()

        if len(mw) == 32:
            if not db.contains_md5(mw):
                url = "http://api.malshare.com/sampleshare.php?" +\
                    "action=getfile&api_key=" + MALSHARE_API_KEY +\
                    "&hash=" + mw
                get_malware([url], "malshare")
                count += 1
            else:
                sys.stdout.write(".")
        sys.stdout.flush()

if __name__ == "__main__":

    vt = virustotalinterface.virustotalinterface(API_KEY)
    db = databaseinterface.databaseinterface(HOST, USER, PASSWORD, DATABASE)

    # Parse command line arguments
    parser = argparse.ArgumentParser(description="Processes suspected " +
        "malware samples, collecting samples and their metadata.")
    parser.add_argument('--scraper', action='store_true',
        help="Crawl blacklists")
    parser.add_argument('--files', type=str, nargs='+',
        help='Add malware files passed in command line')
    parser.add_argument('--file_source', type=str, nargs=1,
        default=['unknown'], help='description of file source')
    parser.add_argument('--malshare', action='store_true',
        help='Get malware from malshare')
    parser.add_argument('--delete', action='store_true',
        help='Delete files after add (--files only)')
    args = parser.parse_args()

    if args.malshare:
        get_malshare()

    if args.scraper:
        # Malware sources is a list of dictionaries:
        malware_sources = [
            {'url':'http://malwareurls.joxeankoret.com/normal.txt',
                'fun':process_text_list, 'args':None, 'desc':'joxeankoret'},
            {'url':'http://www.malwareblacklist.com/mbl.xml',
                'fun':process_rss_description, 'args':'Host: ', 'desc':'MBL'},
            {'url':'http://vxvault.siri-urz.net/URL_List.php',
                'fun': process_text_list, 'args':None, 'desc':'vx-vault'},
            {'url':'https://zeustracker.abuse.ch/monitor.php?urlfeed=binaries',
                'fun':process_rss_description, 'args':'URL: ',
                'desc':'Zeus binaries'},
            {'url':'http://malwaredb.malekal.com/', 'fun':process_malekal_zips,
                'args':1, 'desc':'malekal'},
            {'url':"http://www.malwaredomainlist.com/hostslist/mdl.xml",
                'fun':process_rss_description, 'args':'Host: ', 'desc':'MDL'},
            {'url':'http://malc0de.com/rss/', 'fun':process_rss_description,
                'args':'URL: ', 'desc':'malc0de'},
            {'url':'http://support.clean-mx.de/clean-mx/xmlviruses.php?',
                'fun':process_cleanmx_xml, 'args':None, 'desc':'clean-mx'}
        ]

        perm = list(range(len(malware_sources)))
        random.shuffle(perm)

        for i in perm:
            print('Processing ' + malware_sources[i]['desc'])
            malware_list = malware_sources[i]['fun'](malware_sources[i]['url'],
                malware_sources[i]['args'])
            get_malware(malware_list, malware_sources[i]['desc'])

    if args.files:
        counter = 0
        for fname in args.files:
            counter += 1
            print(str(counter) + "/" + str(len(args.files)) + "\t" + fname)
            with open(fname, 'rb') as f:
                mw = f.read()
                process_malware(mw, args.file_source[0], "none",
                    fname.split('/')[-1].encode('ascii', 'ignore'))

            if args.delete:
                os.remove(fname)
